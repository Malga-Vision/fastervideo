{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyTdFnuhqhZx"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator,PascalVOCDetectionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.tensor as tensor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "import torch\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.modeling.meta_arch.tracker import Tracker\n",
    "from detectron2.modeling.meta_arch.soft_tracker import SoftTracker\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTnx-rVFc-gi"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1577719198991,
     "user": {
      "displayName": "Issa Mouawad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC4MQNrCOLVZp6wyxyAhCMqw8Udn-UEuh66kHi9qw=s64",
      "userId": "16526136313232193808"
     },
     "user_tz": -60
    },
    "id": "6rigOU2Gre3r",
    "outputId": "e25fe68a-a39f-4f76-e9d3-58990208d499"
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "#cfg.MODEL.DEVICE='cpu'\n",
    "cfg.merge_from_file(\"../configs/COCO-Detection/faster_rcnn_R_50_FPN_3x_Video.yaml\")\n",
    "#cfg.merge_from_file(\"./detectron2_repo/configs/COCO-Detection/faster_rcnn_R_50_Video.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES=1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # set threshold for this model\n",
    "#cfg.MODEL.WEIGHTS = \"KITTI_FPN_FINAL/model_final.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"../models_pub/MOT/mot_17.pth\"\n",
    "\n",
    "print(cfg.MODEL)\n",
    "#arr = {1:'cyclist',2:'car',0:'pedestrian'}\n",
    "arr = {0:'Pedestrian'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNcPBUx2c-go"
   },
   "source": [
    "## inference: Joint detection and tracking\n",
    "- fix the hyper parameters (setting)\n",
    "- choose a dataset (train or test of mot17 or mot20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "\n",
    "dirC = '../datasets/MOT/MOT17/train/'\n",
    "names = []\n",
    "\n",
    "\n",
    "settings = [\n",
    "   \n",
    "    \n",
    "    \n",
    " settings = [\n",
    "   \n",
    "    dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "        ),\n",
    "    ]   \n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "]\n",
    "train_folders_17 = ['MOT17-02','MOT17-04','MOT17-05','MOT17-09','MOT17-10','MOT17-11','MOT17-13']\n",
    "test_folders_17 = ['MOT17-01','MOT17-03','MOT17-06','MOT17-07','MOT17-08','MOT17-12','MOT17-14']\n",
    "\n",
    "train_folder_20 = [\"MOT20-01\",\"MOT20-02\",\"MOT20-03\",\"MOT20-05\"]\n",
    "test_folder_20 = [\"MOT20-04\",\"MOT20-06\",\"MOT20-07\",\"MOT20-08\"]\n",
    "\n",
    "mot15_folders = ['MOT17-02','MOT17-04','MOT17-05','MOT17-09','MOT17-10','MOT17-11','MOT17-13']\n",
    "\n",
    "\n",
    "\n",
    "for setting in settings:\n",
    "    \n",
    "    setting_id = setting_id + 1\n",
    "    if(not os.path.exists(\"../results\")):\n",
    "        os.mkdir('../results')\n",
    "        os.mkdir('../results/MOT')\n",
    "    else:\n",
    "        if(not os.path.exists(\"../results/MOT\")):\n",
    "            os.mkdir('../results/MOT')\n",
    "    \n",
    "    output_path = '../results/MOT/MOT20_%s'%(str(setting_id))\n",
    "    \n",
    "    exp_name = output_path\n",
    "    total_elapsed=0\n",
    "    if(not os.path.exists(exp_name)):\n",
    "      os.mkdir(exp_name)\n",
    "      \n",
    "    for folder_name in test_folders_17:\n",
    "    \n",
    "    #for folder_name in os.listdir(dirC):\n",
    "      #out_tracking = cv2.VideoWriter('joint_%s.avi'%folder_name,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1242,375))\n",
    "      \n",
    "      #if(not folder_name in ['0000','0007','0011']):\n",
    "        #continue\n",
    "        \n",
    "      dump_image = cv2.imread(dirC+folder_name+'/img1/000001.jpg')\n",
    "      #out_tracking = cv2.VideoWriter('mot_paper.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, dump_image.shape[1::-1])\n",
    "      predictor = DefaultPredictor(cfg)\n",
    "      #prop_limit=60\n",
    "      predictor.model.tracker = SoftTracker()\n",
    "      print(folder_name)\n",
    "      predictor.model.tracking_proposals = setting['T']\n",
    "      predictor.model.tracker.track_life = setting['track_life']\n",
    "      predictor.model.tracker.track_visibility = setting['track_vis']\n",
    "      predictor.model.tracker.use_appearance = setting['A']\n",
    "      predictor.model.tracker.use_kalman = setting['K']\n",
    "      predictor.model.tracker.hot = setting['H']\n",
    "      predictor.model.tracker.use_color = False\n",
    "      predictor.model.tracker.embed = setting['E']\n",
    "      predictor.model.tracker.reid = setting['Re']\n",
    "      predictor.model.tracker.hog = setting['H']\n",
    "      predictor.model.tracker.measurement_noise=setting['measurement']\n",
    "      predictor.model.tracker.process_noise = setting['process']\n",
    "      predictor.model.enable_clustering=False\n",
    "      predictor.model.tracker.hog_num_cells = setting['hog_cells']\n",
    "      predictor.model.tracker.dist_thresh = setting['dist_thresh']\n",
    "      predictor.model.use_reid = setting['Re']\n",
    "      predictor.model.tracker.soft_thresh = setting['st']\n",
    "      predictor.model.tracker.suppress_fp = setting['sup_fp']\n",
    "      predictor.model.tracker.fp_thresh = setting['fp_thresh']\n",
    "      predictor.model.tracker.embed_alpha = setting['alpha']\n",
    "      \n",
    "      max_distance = 0.2\n",
    "      \n",
    "      \n",
    "      \n",
    "        \n",
    "      output_file = open('%s/%s.txt'%(exp_name,folder_name),'w')\n",
    "      print('%s/%s.txt'%(exp_name,folder_name))\n",
    "      \n",
    "      start = time.time()\n",
    "      frame_counter = 0\n",
    "      prev_path = 0\n",
    "      predictor.model.prev_path = 0\n",
    "      frames = {}\n",
    "      for photo_name in sorted(os.listdir(dirC+folder_name+'/img1/')):\n",
    "        img_path = dirC+folder_name+'/img1/'+photo_name\n",
    "        \n",
    "        frames[frame_counter] = {}\n",
    "        img = cv2.imread(img_path)\n",
    "        inp = {}\n",
    "        inp['width'] = img.shape[1]\n",
    "        inp['height'] = img.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "        inp['file_name'] =  photo_name\n",
    "        inp['image_id'] = photo_name\n",
    "        \n",
    "        predictor.model.photo_name = img_path\n",
    "        \n",
    "        outputs = predictor(img,setting['props'])\n",
    "        \n",
    "       \n",
    "       \n",
    "        for i in outputs:\n",
    "\n",
    "            if(i.pred_class in arr):\n",
    "              \n",
    "              output_file.write(\"%d,%d,%d,%d,%d,%d,%f,-1,-1,-1\\n\"\n",
    "                                %(frame_counter,i.track_id,i.xmin,i.ymin,i.xmax-i.xmin,i.ymax-i.ymin\n",
    "                                  ,i.conf))\n",
    "      \n",
    "        frame_counter +=1\n",
    "        predictor.model.prev_path = img_path\n",
    "\n",
    "      end = time.time()\n",
    "      elapsed = end-start\n",
    "\n",
    "      avg = frame_counter/elapsed\n",
    "      print('avg time is' ,avg)\n",
    "      print('elapsed : ',elapsed)\n",
    "      output_file.close()\n",
    "      total_elapsed += elapsed\n",
    "    print('total elapsed ', total_elapsed)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KITTI Tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
