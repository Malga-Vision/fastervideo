{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyTdFnuhqhZx"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator,PascalVOCDetectionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.tensor as tensor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "import torch\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.modeling.meta_arch.tracker import Tracker\n",
    "from detectron2.modeling.meta_arch.soft_tracker import SoftTracker\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTnx-rVFc-gi"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1577719198991,
     "user": {
      "displayName": "Issa Mouawad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC4MQNrCOLVZp6wyxyAhCMqw8Udn-UEuh66kHi9qw=s64",
      "userId": "16526136313232193808"
     },
     "user_tz": -60
    },
    "id": "6rigOU2Gre3r",
    "outputId": "e25fe68a-a39f-4f76-e9d3-58990208d499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 17:22:57 d2.config.compat]: \u001b[0mConfig '../configs/COCO-Detection/faster_rcnn_R_50_FPN_3x_Video.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "ANCHOR_GENERATOR:\n",
      "  ANGLES: [[-90, 0, 90]]\n",
      "  ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "  NAME: DefaultAnchorGenerator\n",
      "  SIZES: [[32], [64], [128], [256], [512]]\n",
      "BACKBONE:\n",
      "  FREEZE_AT: 2\n",
      "  NAME: build_resnet_fpn_backbone\n",
      "DEVICE: cuda\n",
      "FPN:\n",
      "  FUSE_TYPE: sum\n",
      "  IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "  NORM: \n",
      "  OUT_CHANNELS: 256\n",
      "KEYPOINT_ON: False\n",
      "LOAD_PROPOSALS: False\n",
      "MASK_ON: False\n",
      "META_ARCHITECTURE: VideoRCNN\n",
      "PANOPTIC_FPN:\n",
      "  COMBINE:\n",
      "    ENABLED: True\n",
      "    INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "    OVERLAP_THRESH: 0.5\n",
      "    STUFF_AREA_LIMIT: 4096\n",
      "  INSTANCE_LOSS_WEIGHT: 1.0\n",
      "PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "PROPOSAL_GENERATOR:\n",
      "  MIN_SIZE: 0\n",
      "  NAME: RPN\n",
      "RESNETS:\n",
      "  DEFORM_MODULATED: False\n",
      "  DEFORM_NUM_GROUPS: 1\n",
      "  DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "  DEPTH: 50\n",
      "  NORM: FrozenBN\n",
      "  NUM_GROUPS: 1\n",
      "  OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "  RES2_OUT_CHANNELS: 256\n",
      "  RES5_DILATION: 1\n",
      "  STEM_OUT_CHANNELS: 64\n",
      "  STRIDE_IN_1X1: True\n",
      "  WIDTH_PER_GROUP: 64\n",
      "RETINANET:\n",
      "  BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "  FOCAL_LOSS_ALPHA: 0.25\n",
      "  FOCAL_LOSS_GAMMA: 2.0\n",
      "  IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "  IOU_LABELS: [0, -1, 1]\n",
      "  IOU_THRESHOLDS: [0.4, 0.5]\n",
      "  NMS_THRESH_TEST: 0.5\n",
      "  NUM_CLASSES: 80\n",
      "  NUM_CONVS: 4\n",
      "  PRIOR_PROB: 0.01\n",
      "  SCORE_THRESH_TEST: 0.05\n",
      "  SMOOTH_L1_LOSS_BETA: 0.1\n",
      "  TOPK_CANDIDATES_TEST: 1000\n",
      "ROI_BOX_CASCADE_HEAD:\n",
      "  BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "  IOUS: (0.5, 0.6, 0.7)\n",
      "ROI_BOX_HEAD:\n",
      "  BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  CONV_DIM: 256\n",
      "  FC_DIM: 1024\n",
      "  NAME: FastRCNNConvFCHead\n",
      "  NORM: \n",
      "  NUM_CONV: 0\n",
      "  NUM_FC: 2\n",
      "  POOLER_RESOLUTION: 7\n",
      "  POOLER_SAMPLING_RATIO: 0\n",
      "  POOLER_TYPE: ROIAlignV2\n",
      "  SMOOTH_L1_BETA: 0.0\n",
      "ROI_HEADS:\n",
      "  BATCH_SIZE_PER_IMAGE: 512\n",
      "  IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "  IOU_LABELS: [0, 1]\n",
      "  IOU_THRESHOLDS: [0.5]\n",
      "  NAME: StandardROIHeads\n",
      "  NMS_THRESH_TEST: 0.5\n",
      "  NUM_CLASSES: 1\n",
      "  POSITIVE_FRACTION: 0.25\n",
      "  PROPOSAL_APPEND_GT: True\n",
      "  SCORE_THRESH_TEST: 0.4\n",
      "ROI_KEYPOINT_HEAD:\n",
      "  CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "  LOSS_WEIGHT: 1.0\n",
      "  MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "  NAME: KRCNNConvDeconvUpsampleHead\n",
      "  NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "  NUM_KEYPOINTS: 17\n",
      "  POOLER_RESOLUTION: 14\n",
      "  POOLER_SAMPLING_RATIO: 0\n",
      "  POOLER_TYPE: ROIAlignV2\n",
      "ROI_MASK_HEAD:\n",
      "  CLS_AGNOSTIC_MASK: False\n",
      "  CONV_DIM: 256\n",
      "  NAME: MaskRCNNConvUpsampleHead\n",
      "  NORM: \n",
      "  NUM_CONV: 4\n",
      "  POOLER_RESOLUTION: 14\n",
      "  POOLER_SAMPLING_RATIO: 0\n",
      "  POOLER_TYPE: ROIAlignV2\n",
      "RPN:\n",
      "  BATCH_SIZE_PER_IMAGE: 256\n",
      "  BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "  BOUNDARY_THRESH: -1\n",
      "  HEAD_NAME: StandardRPNHead\n",
      "  IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "  IOU_LABELS: [0, -1, 1]\n",
      "  IOU_THRESHOLDS: [0.3, 0.7]\n",
      "  LOSS_WEIGHT: 1.0\n",
      "  NMS_THRESH: 0.7\n",
      "  POSITIVE_FRACTION: 0.5\n",
      "  POST_NMS_TOPK_TEST: 1000\n",
      "  POST_NMS_TOPK_TRAIN: 1000\n",
      "  PRE_NMS_TOPK_TEST: 1000\n",
      "  PRE_NMS_TOPK_TRAIN: 2000\n",
      "  SMOOTH_L1_BETA: 0.0\n",
      "SEM_SEG_HEAD:\n",
      "  COMMON_STRIDE: 4\n",
      "  CONVS_DIM: 128\n",
      "  IGNORE_VALUE: 255\n",
      "  IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "  LOSS_WEIGHT: 1.0\n",
      "  NAME: SemSegFPNHead\n",
      "  NORM: GN\n",
      "  NUM_CLASSES: 54\n",
      "WEIGHTS: /media/DATA/Users/Issa/Models/MOT17_JDE/model_final.pth\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "#cfg.MODEL.DEVICE='cpu'\n",
    "cfg.merge_from_file(\"../configs/COCO-Detection/faster_rcnn_R_50_FPN_3x_Video.yaml\")\n",
    "#cfg.merge_from_file(\"./detectron2_repo/configs/COCO-Detection/faster_rcnn_R_50_Video.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES=1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # set threshold for this model\n",
    "#cfg.MODEL.WEIGHTS = \"KITTI_FPN_FINAL/model_final.pth\"\n",
    "cfg.MODEL.WEIGHTS=\"/media/DATA/Users/Issa/Models/MOT17_JDE/model_final.pth\"\n",
    "#cfg.MODEL.WEIGHTS = \"../models_pub/MOT/mot_17.pth\"\n",
    "\n",
    "print(cfg.MODEL)\n",
    "#arr = {1:'cyclist',2:'car',0:'pedestrian'}\n",
    "arr = {0:'Pedestrian'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNcPBUx2c-go"
   },
   "source": [
    "## inference: Joint detection and tracking\n",
    "- fix the hyper parameters (setting)\n",
    "- choose a dataset (train or test of mot17 or mot20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOT16-02\n",
      "../results/MOT/MOT17_1/MOT16-02.txt\n",
      "avg time is 5.613375569725861\n",
      "elapsed :  106.88755679130554\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_1/MOT16-05.txt\n",
      "avg time is 8.978063935412917\n",
      "elapsed :  93.2272264957428\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_1/MOT16-10.txt\n",
      "avg time is 5.658884010627024\n",
      "elapsed :  115.57049036026001\n",
      "total elapsed  315.68527364730835\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_2/MOT16-02.txt\n",
      "avg time is 5.5248545815437184\n",
      "elapsed :  108.60014343261719\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_2/MOT16-05.txt\n",
      "avg time is 8.94762852786005\n",
      "elapsed :  93.54433941841125\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_2/MOT16-10.txt\n",
      "avg time is 5.65673499225001\n",
      "elapsed :  115.61439609527588\n",
      "total elapsed  317.7588789463043\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_3/MOT16-02.txt\n",
      "avg time is 5.536438266303821\n",
      "elapsed :  108.37292337417603\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_3/MOT16-05.txt\n",
      "avg time is 8.91052029640067\n",
      "elapsed :  93.933908700943\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_3/MOT16-10.txt\n",
      "avg time is 5.623800414122251\n",
      "elapsed :  116.29146695137024\n",
      "total elapsed  318.59829902648926\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_4/MOT16-02.txt\n",
      "avg time is 5.51507403151113\n",
      "elapsed :  108.79273724555969\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_4/MOT16-05.txt\n",
      "avg time is 8.890284187516103\n",
      "elapsed :  94.14772152900696\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_4/MOT16-10.txt\n",
      "avg time is 5.560854597531607\n",
      "elapsed :  117.60782241821289\n",
      "total elapsed  320.54828119277954\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_5/MOT16-02.txt\n",
      "avg time is 5.443864364809526\n",
      "elapsed :  110.21582460403442\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_5/MOT16-05.txt\n",
      "avg time is 8.861458227189054\n",
      "elapsed :  94.45398020744324\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_5/MOT16-10.txt\n",
      "avg time is 5.513813770027158\n",
      "elapsed :  118.61118769645691\n",
      "total elapsed  323.28099250793457\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_6/MOT16-02.txt\n",
      "avg time is 5.36271197774444\n",
      "elapsed :  111.88368916511536\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_6/MOT16-05.txt\n",
      "avg time is 8.8477504337452\n",
      "elapsed :  94.60031747817993\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_6/MOT16-10.txt\n",
      "avg time is 5.446335730508792\n",
      "elapsed :  120.08073544502258\n",
      "total elapsed  326.56474208831787\n",
      "MOT16-02\n",
      "../results/MOT/MOT17_7/MOT16-02.txt\n",
      "avg time is 5.284841298598202\n",
      "elapsed :  113.53226447105408\n",
      "MOT16-05\n",
      "../results/MOT/MOT17_7/MOT16-05.txt\n",
      "avg time is 8.837032720191926\n",
      "elapsed :  94.71505045890808\n",
      "MOT16-10\n",
      "../results/MOT/MOT17_7/MOT16-10.txt\n",
      "avg time is 5.311034458755565\n",
      "elapsed :  123.13985252380371\n",
      "total elapsed  331.38716745376587\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "\n",
    "dirC = '/media/DATA/Datasets/MOT/MOT17/train/'\n",
    "names = []\n",
    "setting_id = 0\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "settings = [\n",
    "   \n",
    "    dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.3\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.4\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.5\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.6\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.7\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.8\n",
    "        ),\n",
    "     dict(props=50, #number of proposals to use by rpn\n",
    "         st=1.05, #acceptance distance percentage for soft tracker\n",
    "         sup_fp = False, # fp suppression based on Intersection over Union for new detections\n",
    "         alpha = 0.6, # the percentage of the new embedding in track embedding update (emb = alpha * emb(t) +(1-alpha) emb(t-1)) \n",
    "         fp_thresh=0.95, # iou threshold above which the new detection is considered a fp\n",
    "         T=True, #use past tracks as proposals\n",
    "         D='cosine', # distance metric for embeddings\n",
    "         Re=True, #use the embedding head \n",
    "         A=True, # use appearance information\n",
    "         H=False, # use HOG features as appearance descriptors\n",
    "         K=True, # use kalman for motion prediction\n",
    "         E=False, #use raw FPN features as appearance descriptors\n",
    "         measurement=0.001, #measruement noise for the kalman filter\n",
    "         process=1, #process noise for the kalman filter\n",
    "         hog_cells=4, #number of cells used to calculate hof features\n",
    "         dist_thresh=1.5, # the normalization factor for the appearance distance\n",
    "         track_life=7, #frames for which a track is kept in memory without an update\n",
    "         track_vis=2, #frames for which a track is displayed without an update\n",
    "         giou_cutoff = -0.9\n",
    "        ),\n",
    "    ]   \n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "train_folders_17 = ['MOT17-02','MOT17-04','MOT17-05','MOT17-09','MOT17-10','MOT17-11','MOT17-13']\n",
    "test_folders_17 = ['MOT17-01','MOT17-03','MOT17-06','MOT17-07','MOT17-08','MOT17-12','MOT17-14']\n",
    "\n",
    "train_folder_20 = [\"MOT20-01\",\"MOT20-02\",\"MOT20-03\",\"MOT20-05\"]\n",
    "test_folder_20 = [\"MOT20-04\",\"MOT20-06\",\"MOT20-07\",\"MOT20-08\"]\n",
    "\n",
    "mot15_folders = ['MOT17-02','MOT17-04','MOT17-05','MOT17-09','MOT17-10','MOT17-11','MOT17-13']\n",
    "\n",
    "\n",
    "\n",
    "for setting in settings:\n",
    "    \n",
    "    setting_id = setting_id + 1\n",
    "    if(not os.path.exists(\"../results\")):\n",
    "        os.mkdir('../results')\n",
    "        os.mkdir('../results/MOT')\n",
    "    else:\n",
    "        if(not os.path.exists(\"../results/MOT\")):\n",
    "            os.mkdir('../results/MOT')\n",
    "    \n",
    "    output_path = '../results/MOT/MOT17_%s'%(str(setting_id))\n",
    "    \n",
    "    exp_name = output_path\n",
    "    total_elapsed=0\n",
    "    if(not os.path.exists(exp_name)):\n",
    "      os.mkdir(exp_name)\n",
    "      \n",
    "    for folder_name in [\"MOT16-02\",\"MOT16-05\",\"MOT16-10\"]:\n",
    "    \n",
    "    #for folder_name in os.listdir(dirC):\n",
    "      #out_tracking = cv2.VideoWriter('joint_%s.avi'%folder_name,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1242,375))\n",
    "      \n",
    "      #if(not folder_name in ['0000','0007','0011']):\n",
    "        #continue\n",
    "        \n",
    "      dump_image = cv2.imread(dirC+folder_name+'/img1/000001.jpg')\n",
    "      #out_tracking = cv2.VideoWriter('mot_paper.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, dump_image.shape[1::-1])\n",
    "      predictor = DefaultPredictor(cfg)\n",
    "      #prop_limit=60\n",
    "      predictor.model.tracker = SoftTracker()\n",
    "      print(folder_name)\n",
    "      predictor.model.tracking_proposals = setting['T']\n",
    "      predictor.model.tracker.track_life = setting['track_life']\n",
    "      predictor.model.tracker.track_visibility = setting['track_vis']\n",
    "      predictor.model.tracker.use_appearance = setting['A']\n",
    "      predictor.model.tracker.use_kalman = setting['K']\n",
    "      predictor.model.tracker.hot = setting['H']\n",
    "      predictor.model.tracker.use_color = False\n",
    "      predictor.model.tracker.embed = setting['E']\n",
    "      predictor.model.tracker.reid = setting['Re']\n",
    "      predictor.model.tracker.hog = setting['H']\n",
    "      predictor.model.tracker.measurement_noise=setting['measurement']\n",
    "      predictor.model.tracker.process_noise = setting['process']\n",
    "      predictor.model.enable_clustering=False\n",
    "      predictor.model.tracker.giou_cutoff = setting['giou_cutoff']\n",
    "      predictor.model.tracker.hog_num_cells = setting['hog_cells']\n",
    "      predictor.model.tracker.dist_thresh = setting['dist_thresh']\n",
    "      predictor.model.use_reid = setting['Re']\n",
    "      predictor.model.tracker.dist = 'cosine'\n",
    "      predictor.model.tracker.soft_thresh = setting['st']\n",
    "      predictor.model.tracker.suppress_fp = setting['sup_fp']\n",
    "      predictor.model.tracker.fp_thresh = setting['fp_thresh']\n",
    "      predictor.model.tracker.embed_alpha = setting['alpha']\n",
    "      \n",
    "      max_distance = 0.2\n",
    "      \n",
    "      \n",
    "      \n",
    "        \n",
    "      output_file = open('%s/%s.txt'%(exp_name,folder_name),'w')\n",
    "      print('%s/%s.txt'%(exp_name,folder_name))\n",
    "      \n",
    "      start = time.time()\n",
    "      frame_counter = 0\n",
    "      prev_path = 0\n",
    "      predictor.model.prev_path = 0\n",
    "      frames = {}\n",
    "      for photo_name in sorted(os.listdir(dirC+folder_name+'/img1/')):\n",
    "        img_path = dirC+folder_name+'/img1/'+photo_name\n",
    "        \n",
    "        frames[frame_counter] = {}\n",
    "        img = cv2.imread(img_path)\n",
    "        inp = {}\n",
    "        inp['width'] = img.shape[1]\n",
    "        inp['height'] = img.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "        inp['file_name'] =  photo_name\n",
    "        inp['image_id'] = photo_name\n",
    "        \n",
    "        predictor.model.photo_name = img_path\n",
    "        \n",
    "        outputs = predictor(img,setting['props'])\n",
    "        \n",
    "       \n",
    "       \n",
    "        for i in outputs:\n",
    "\n",
    "            if(i.pred_class in arr):\n",
    "              \n",
    "              output_file.write(\"%d,%d,%d,%d,%d,%d,%f,-1,-1,-1\\n\"\n",
    "                                %(frame_counter,i.track_id,i.xmin,i.ymin,i.xmax-i.xmin,i.ymax-i.ymin\n",
    "                                  ,i.conf))\n",
    "      \n",
    "        frame_counter +=1\n",
    "        predictor.model.prev_path = img_path\n",
    "\n",
    "      end = time.time()\n",
    "      elapsed = end-start\n",
    "\n",
    "      avg = frame_counter/elapsed\n",
    "      print('avg time is' ,avg)\n",
    "      print('elapsed : ',elapsed)\n",
    "      output_file.close()\n",
    "      total_elapsed += elapsed\n",
    "    print('total elapsed ', total_elapsed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KITTI Tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
