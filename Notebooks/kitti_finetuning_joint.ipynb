{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI Joint Detection and Embedding Finetuning\n",
    "### This notebook is used to lunch the finetuning of FPN on KITTI joint detection and embedding using the tracking ground truth, the code uses weights of the object detector trained previously (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7bJ1j_ygxPx"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator,PascalVOCDetectionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.tensor as tensor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "import torch\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.modeling import build_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../datasets/KITTI/tracking/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "def get_kitti_joint(path):\n",
    "    dict_arr = []\n",
    "    triplet_boxes = {}\n",
    "    img_folder = path + 'data_tracking_image_2/training/image_02/'\n",
    "    label_folder = path + 'data_tracking_label_2/training/label_02/' \n",
    "    for seq_name in os.listdir(img_folder):\n",
    "        with open('%s%s.txt'%(label_folder,seq_name)) as f:\n",
    "            for line in f:\n",
    "                parts = line.split(' ')\n",
    "                frame_number = int(parts[0])\n",
    "\n",
    "        frames = [None]*(frame_number+1)\n",
    "        boxes = [None] *(frame_number +1)\n",
    "        for i in range(len(boxes)):\n",
    "            boxes[i] = {}\n",
    "            frames[i] =[]\n",
    "        with open('%s%s.txt'%(label_folder,seq_name)) as f:\n",
    "            for line in f:\n",
    "                parts = line.split(' ')\n",
    "                frame_number = int(parts[0])\n",
    "                cat = -1\n",
    "                if(parts[2] == 'Car' or parts[2] == 'Van'):\n",
    "                    cat = 0\n",
    "                \n",
    "                \n",
    "                if(cat>-1):\n",
    "                    \n",
    "                    frames[frame_number].append(int(parts[1]))\n",
    "                    xmin = int(float(parts[6]))\n",
    "                    ymin = int(float(parts[7]))\n",
    "                    xmax = int(float(parts[8]))\n",
    "                    ymax = int(float(parts[9]))\n",
    "                    key = parts[1]\n",
    "                    if(cat==0):\n",
    "                        key = '-'+parts[1]\n",
    "                    \n",
    "                    boxes[frame_number][parts[1]] =   {'bbox':[xmin,ymin,xmax,ymax\n",
    "                                                                   ],\"img_number\":parts[0], \"obj_id\": parts[1],\"category_id\": cat,\n",
    "                                                            \"iscrowd\": 0,\"bbox_mode\": BoxMode.XYXY_ABS} \n",
    "        \n",
    "        frame_set = []\n",
    "        for f in frames:\n",
    "            if(f is not None):\n",
    "                frame_set.append(set(f))\n",
    "        \n",
    "        import random\n",
    "        \n",
    "        frame_order = list(np.arange(0,len(frame_set))) + list(np.arange(0,len(frame_set)))+  list(np.arange(0,len(frame_set)))+list(np.arange(0,len(frame_set)))+list(np.arange(0,len(frame_set)))\n",
    "        i =0\n",
    "        useful = 0\n",
    "        accum_intersect = []\n",
    "        \n",
    "        while i < (len(frame_set)*5 -16):\n",
    "            freqs = {}\n",
    "            ids_to_keep = random.sample(frame_order[i:i+16],k=8)\n",
    "            \n",
    "            for frame_ids in [frame_set[k] for k in ids_to_keep]:\n",
    "                for t_id in frame_ids:\n",
    "                    if(t_id not in freqs):\n",
    "                        freqs[t_id] =0\n",
    "                    freqs[t_id] +=1\n",
    "            okay = np.where(np.array([freqs[k] for k in freqs.keys()])>=4)[0].shape[0]\n",
    "            \n",
    "            \n",
    "            base_url = '%s%s/'%(img_folder,seq_name)\n",
    "            if(okay>=8):\n",
    "                pairs_used = [k for k in freqs.keys() if freqs[k]>=4]\n",
    "                \n",
    "                frame_number = 0\n",
    "                frame_group = []\n",
    "                while frame_number <8:\n",
    "                    obj = {}\n",
    "                    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "                    obj['file_name'] = base_url+'%s.png'%str(ids_to_keep[frame_number]).zfill(6) \n",
    "                    \n",
    "                    temp_img = cv2.imread(obj['file_name'])\n",
    "                    obj['width'] = temp_img.shape[1]\n",
    "                    obj['height'] = temp_img.shape[0]\n",
    "                    name_split = obj['file_name'].split('/')\n",
    "                    obj[\"image_id\"] = int(name_split[len(name_split)-1].split('.')[0])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    car_keys = []\n",
    "                    for k in boxes[ids_to_keep[frame_number]].keys():\n",
    "                        if(boxes[ids_to_keep[frame_number]][k][\"category_id\"]==2):\n",
    "                            car_keys.append(int(k))\n",
    "                    ordered_keys = []\n",
    "                    first_keys = []\n",
    "                    second_keys = []\n",
    "                    for k in boxes[ids_to_keep[frame_number]].keys():\n",
    "                        if(int(k) in accum_intersect):\n",
    "                            first_keys.append(str(k))\n",
    "                        else:\n",
    "                            second_keys.append(str(k))\n",
    "                    ordered_keys = first_keys + second_keys\n",
    "                    obj[\"ids\"] = [int(k) for k in boxes[ids_to_keep[frame_number]].keys()]\n",
    "                    obj[\"classes\"] = [int(boxes[ids_to_keep[frame_number]][k]['category_id']) for k in boxes[ids_to_keep[frame_number]].keys()]\n",
    "                    obj[\"pairs_used\"] = pairs_used\n",
    "                    obj[\"annotations\"]= ([boxes[ids_to_keep[frame_number]][str(k)] for k in ordered_keys])\n",
    "                    \n",
    "                    \n",
    "                    obj[\"labels\"] = []\n",
    "                    list_labels = list(accum_intersect.copy()) \n",
    "                    for l in list_labels:\n",
    "                        obj[\"labels\"].append(l)\n",
    "                 \n",
    "                    dict_arr.append(obj)\n",
    "                    \n",
    "                    frame_number +=1\n",
    "                    frame_group.append(obj['image_id'])\n",
    "            \n",
    "            i=i+1   \n",
    "        \n",
    "    return dict_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yumbl96BoUWt"
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "for d in [\"train\"]:\n",
    "    DatasetCatalog.register(\"kitti_\" + d, lambda d=d: get_kitti_joint(data_path))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "cfg = get_cfg()\n",
    "#cfg.merge_from_file(\"./detectron2_repo/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
    "cfg.merge_from_file(\"../configs/COCO-Detection/faster_rcnn_R_50_FPN_3x_Video.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"kitti_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS=\"../models/KITTI/KITTI_DET/model_final.pth\"\n",
    "\n",
    "#cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_C4_3x/137849393/model_final_f97cb7.pkl\"  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.0009  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 25000  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =1\n",
    "  # only has one class (ballon)\n",
    "cfg.OUTPUT_DIR='../models/KITTI/KITTI_JOINT'\n",
    "print(cfg.OUTPUT_DIR)\n",
    "print(cfg.MODEL.ANCHOR_GENERATOR)\n",
    "print(cfg.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.MODEL.ANCHOR_GENERATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1680576,
     "status": "ok",
     "timestamp": 1579085568597,
     "user": {
      "displayName": "Issa Mouawad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC4MQNrCOLVZp6wyxyAhCMqw8Udn-UEuh66kHi9qw=s64",
      "userId": "16526136313232193808"
     },
     "user_tz": -60
    },
    "id": "i1eMHN9LiTqL",
    "outputId": "1ebedd7e-522e-482d-f3e4-c3e8b9bdb84b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS=[[0.25,0.5,1,2]]\n",
    "#cfg.MODEL.ANCHOR_GENERATOR.SIZES=[[32,64,128,256,512]]\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg,True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNiw1rmxSMUz901Z8O+MdyR",
   "collapsed_sections": [],
   "name": "KITTI Finetuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
