{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOT Joint Detection and Embedding Finetuning\n",
    "### This notebook is used to lunch the finetuning of FPN on MOT joint detection and embedding using the tracking ground truth, the code uses weights of the object detector trained previously (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the mot challenge to work with (two are available)\n",
    "mot_datasets = [\"MOT17\",\"MOT20\"]\n",
    "dataset = mot_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='../datasets/MOT/%s/train/'%dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7bJ1j_ygxPx"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator,PascalVOCDetectionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.tensor as tensor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "import torch\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.modeling import build_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "def get_mot_joint(path,P=8,K=4):\n",
    "    dict_arr = []\n",
    "    \n",
    "\n",
    "    for seq_name in os.listdir(path) :\n",
    "        frame_number = len(os.listdir(path+seq_name+'/img1'))\n",
    "\n",
    "        frames = [None]*(frame_number+1)\n",
    "        boxes = [None] *(frame_number +1)\n",
    "        for i in range(len(boxes)):\n",
    "            boxes[i] = {}\n",
    "            frames[i] =[]\n",
    "        with open(path + seq_name+ '/gt/gt.txt') as f:\n",
    "            for line in f:\n",
    "                parts = line.split(',')\n",
    "                frame_number = int(parts[0])\n",
    "                \n",
    "                if int(parts[6]) == 1 and int(parts[7]) == 1 and float(parts[8]) >= 0.25:\n",
    "                    \n",
    "                    \n",
    "                    frames[frame_number].append(int(parts[1]))\n",
    "                  \n",
    "                    xmin = int(round(float(parts[2])))\n",
    "                    ymin = int(round(float(parts[3])))\n",
    "                    box_width = int(round(float(parts[4])))\n",
    "                    box_height = int(round(float(parts[5])))\n",
    "                    xmax = xmin+ box_width\n",
    "                    ymax = ymin + box_height\n",
    "                    key = parts[1]\n",
    "                    \n",
    "                    \n",
    "                    boxes[frame_number][parts[1]] =   {'bbox':[xmin,ymin,xmax,ymax\n",
    "                                                                   ],\"img_number\":parts[0], \"obj_id\": parts[1],\"category_id\": 0,\n",
    "                                                            \"iscrowd\": 0,\"bbox_mode\": BoxMode.XYXY_ABS} \n",
    "        \n",
    "        frame_set = []\n",
    "        for f in frames:\n",
    "            if(f is not None):\n",
    "                frame_set.append(set(f))\n",
    "        \n",
    "        import random\n",
    "        frame_order1 = np.arange(0,len(frame_set))\n",
    "        random.shuffle(frame_order1)\n",
    "        frame_order2 = np.arange(0,len(frame_set))\n",
    "        random.shuffle(frame_order2)\n",
    "        frame_order3 = np.arange(0,len(frame_set))\n",
    "        random.shuffle(frame_order3)\n",
    "        frame_order4 = np.arange(0,len(frame_set))\n",
    "        random.shuffle(frame_order4)\n",
    "        \n",
    "        frame_order = list(frame_order1)+list(frame_order2)+list(frame_order3)+list(frame_order4)\n",
    "        frame_order1 = np.arange(1,len(frame_set))\n",
    "        random.shuffle(frame_order1)\n",
    "        frame_order2 = np.arange(1,len(frame_set))\n",
    "        random.shuffle(frame_order2)\n",
    "        frame_order3 = np.arange(1,len(frame_set))\n",
    "        random.shuffle(frame_order3)\n",
    "        frame_order4 = np.arange(1,len(frame_set))\n",
    "        random.shuffle(frame_order4)\n",
    "        frame_order = list(np.arange(1,len(frame_set)))# + list(np.arange(1,len(frame_set)))+ list(np.arange(1,len(frame_set)))\n",
    "        i =0\n",
    "        useful = 0\n",
    "        accum_intersect = []\n",
    "        \n",
    "        while i < (len(frame_set)*1 -16):\n",
    "            freqs = {}\n",
    "            ids_to_keep = random.sample(frame_order[i:i+16],k=P)\n",
    "            \n",
    "            for frame_ids in [frame_set[k] for k in ids_to_keep]:\n",
    "                for t_id in frame_ids:\n",
    "                    if(t_id not in freqs):\n",
    "                        freqs[t_id] =0\n",
    "                    freqs[t_id] +=1\n",
    "            okay = np.where(np.array([freqs[k] for k in freqs.keys()])>=K)[0].shape[0]\n",
    "            \n",
    "            base_url = path + seq_name + '/img1/'\n",
    "            if(okay>=P):\n",
    "                pairs_used = [k for k in freqs.keys() if freqs[k]>=K][0:P]\n",
    "                \n",
    "                frame_number = 0\n",
    "                frame_group = []\n",
    "                while frame_number <P:\n",
    "                    obj = {}\n",
    "                    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "                    obj['file_name'] = base_url+'%s.jpg'%str(ids_to_keep[frame_number]).zfill(6) \n",
    "                    \n",
    "                    temp_img = cv2.imread(obj['file_name'])\n",
    "                    if(temp_img is None):\n",
    "                        print(obj['file_name'])\n",
    "                    obj['width'] = temp_img.shape[1]\n",
    "                    obj['height'] = temp_img.shape[0]\n",
    "                    obj[\"image_id\"] = [i+frame_number]\n",
    "                    obj[\"group_id\"] = i\n",
    "                    \n",
    "                    \n",
    "                    car_keys = []\n",
    "                    \n",
    "                   \n",
    "                    for k in boxes[ids_to_keep[frame_number]].keys():\n",
    "                        if(boxes[ids_to_keep[frame_number]][k][\"category_id\"]==0):\n",
    "                            car_keys.append(int(k))\n",
    "                    ordered_keys = []\n",
    "                    first_keys = []\n",
    "                    second_keys = []\n",
    "                    for k in boxes[ids_to_keep[frame_number]].keys():\n",
    "                        if(int(k) in accum_intersect):\n",
    "                            first_keys.append(str(k))\n",
    "                        else:\n",
    "                            second_keys.append(str(k))\n",
    "                    \n",
    "\n",
    "                    ordered_keys = first_keys + second_keys\n",
    "                    obj[\"ids\"] = [int(k) for k in boxes[ids_to_keep[frame_number]].keys()]\n",
    "                    obj[\"classes\"] = [int(boxes[ids_to_keep[frame_number]][k]['category_id']) for k in boxes[ids_to_keep[frame_number]].keys()]\n",
    "                    obj[\"pairs_used\"] = pairs_used\n",
    "                    obj[\"annotations\"]= ([boxes[ids_to_keep[frame_number]][str(k)] for k in ordered_keys])\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    obj[\"labels\"] = []\n",
    "                    list_labels = list(accum_intersect.copy()) \n",
    "                    for l in list_labels:\n",
    "                        obj[\"labels\"].append(l)\n",
    "                        \n",
    "                    dict_arr.append(obj)\n",
    "                    frame_number +=1\n",
    "                    frame_group.append(obj['image_id'])\n",
    "                \n",
    "            i=i+1\n",
    "            \n",
    "        break   \n",
    "    \n",
    "    return dict_arr\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yumbl96BoUWt"
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "for d in [\"train\"]:\n",
    "    DatasetCatalog.register(\"%s_\"%dataset + d,\n",
    "                            lambda d=d: \n",
    "                            get_mot_joint\n",
    "                            (data_path))\n",
    "    \n",
    "balloon_metadata = MetadataCatalog.get(\"mot20_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/COCO-Detection/faster_rcnn_R_50_FPN_3x_Video.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"%s_train\"%dataset,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.WEIGHTS=\"../models/MOT/%s_DET/model_final.pth\"%dataset\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES=1\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.00005  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 34000  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "\n",
    "cfg.OUTPUT_DIR='../models/MOT/%s_JOINT'%dataset\n",
    "print(cfg.OUTPUT_DIR)\n",
    "print(cfg.MODEL.ANCHOR_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer initialization and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1680576,
     "status": "ok",
     "timestamp": 1579085568597,
     "user": {
      "displayName": "Issa Mouawad",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC4MQNrCOLVZp6wyxyAhCMqw8Udn-UEuh66kHi9qw=s64",
      "userId": "16526136313232193808"
     },
     "user_tz": -60
    },
    "id": "i1eMHN9LiTqL",
    "outputId": "1ebedd7e-522e-482d-f3e4-c3e8b9bdb84b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg,True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNiw1rmxSMUz901Z8O+MdyR",
   "collapsed_sections": [],
   "name": "KITTI Finetuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
